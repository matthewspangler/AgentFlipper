"""
Processes user requests and interacts with the Flipper Zero and LLM agents.
"""

import logging
from typing import Optional, List, Tuple

from hardware.hardware_manager import FlipperZeroManager
from agent import LLMAgent

logger = logging.getLogger("AgentFlipper")

async def process_user_request(app_instance, user_input: str, flipper_agent: FlipperZeroManager, llm_agent: LLMAgent, recursion_depth: int = 0):
    """
    Process a user request and execute any tool calls.
    Args:
        app_instance: The TextualApp instance for UI updates.
        user_input: The user's input text
        flipper_agent: The agent that communicates with Flipper Zero
        llm_agent: The agent that generates tool calls using LLM
        recursion_depth: Current recursion depth for follow-up tool calls

    Returns:
        None
    """
    # Guard against excessive recursion
    if recursion_depth >= llm_agent.max_recursion_depth:
        logger.warning(f"Maximum recursion depth reached ({llm_agent.max_recursion_depth}), stopping chain")
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nMaximum loop depth reached ({llm_agent.max_recursion_depth}). Please issue a new command to continue.")
        # Generate a final summary when we stop due to recursion limit
        summary = await llm_agent.generate_summary() # Await the async summary generation
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nFinal Summary:")
        await app_instance.display_message(f"{summary}\n")
        return

    # Generate summary every 3 iterations to keep context fresh
    if recursion_depth > 0 and recursion_depth % 3 == 0:
        summary = await llm_agent.generate_summary() # Await the async summary generation
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nProgress Summary:")
        await app_instance.display_message(f"{summary}\n")

    # Check device connection before proceeding
    if not flipper_agent.is_connected:
        logger.error("Device is not connected. Attempting reconnection...")
        reconnect_success = flipper_agent.connect()
        if not reconnect_success:
            await app_instance.display_message(f"[bold red]ERROR: Cannot connect to Flipper Zero device. Please check your connection and try again.[/bold red]")
            return
        else:
            await app_instance.display_message(f"[green]Successfully reconnected to Flipper Zero.[/green]")
    
    # Get tool calls from LLM
    tool_calls = await llm_agent.get_commands(user_input) # Await the async LLM call

    # Handle empty response
    if not tool_calls:
        logger.warning("No tool calls were generated by the LLM")
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nNo response was generated. Try rephrasing your request.")
        return

    # Process each tool call
    for call in tool_calls:
        name = call["name"]
        args = call["arguments"]

        if name == "execute_commands":
            commands = args["commands"]
            # Execute commands and get results
            # Remove color and bold markup to use default orange foreground
            await app_instance.display_message(f"{'─' * 79}")
            await app_instance.display_message(f"Executing {len(commands)} commands...")
            for i, cmd in enumerate(commands, 1):
                await app_instance.display_message(f"{i}. {cmd}")
            await app_instance.display_message(f"{'─' * 79}")
            # Pass the app_instance to execute_commands for direct UI updates
            results = await flipper_agent.execute_commands(commands, app_instance) # Await the async Flipper call, pass app_instance

            # Check for command errors
            command_failed = False
            for cmd, resp in results:
                if "error" in resp.lower() or "illegal" in resp.lower():
                    command_failed = True
                    break

            # Add results to conversation history for better summaries
            llm_agent.add_execution_results_to_history(results) # This method is synchronous and does not need await

            # If command failed, provide error information
            if command_failed:
                error_info = "Command execution failed. Please check the device response."
                await app_instance.display_message(f"[red]{'─' * 79}[/red]")
                await app_instance.display_message(f"[red bold]# Error:[/]")
                await app_instance.display_message(f"[bold red]{error_info}[/]")
                await app_instance.display_message(f"[red]{'─' * 79}[/red]")

        elif name == "provide_information":
            information = args["information"]
            # Display information to user
            # Remove color and bold markup to use default orange foreground
            await app_instance.display_message(f"{'─' * 79}")
            await app_instance.display_message(f"# Information:")
            await app_instance.display_message(f"{information}")
            await app_instance.display_message(f"{'─' * 79}")

        elif name == "ask_question":
            question = args["question"]
            # Ask user question - this will need further Textual integration
            # Remove color markup to use default orange foreground
            await app_instance.display_message(f"{'─' * 79}")
            await app_instance.display_message(f"? {question}")
            await app_instance.display_message(f"{'─' * 79}")
            # Returning here pauses processing for user input in the original UI.
            # In Textual, handling user input is asynchronous. This part needs
            # significant refactoring to work with Textual's input handling.
            # For now, we'll just display the question.
            return  # Cannot pause execution synchronously in Textual worker

        elif name == "mark_task_complete":
            # Mark task as complete
            # Remove color markup to use default orange foreground
            await app_instance.display_message(f"{'─' * 79}")
            await app_instance.display_message(f"✓ Task completed ")
            await app_instance.display_message(f"{'─' * 79}")
            llm_agent.task_in_progress = False
            llm_agent.task_description = ""
            return True  # Indicate task completion

    # If we get here, we processed all tool calls without completing the task or asking a question
    # Check if we executed any commands - if so, force task completion to prevent infinite loops
    command_executed = any(call["name"] == "execute_commands" for call in tool_calls)
    task_completed = any(call["name"] == "mark_task_complete" for call in tool_calls)

    if command_executed and not task_completed and recursion_depth > 0:
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nCommand executed but task not marked complete. Forcing completion to prevent loop.")
        llm_agent.task_in_progress = False
        llm_agent.task_description = ""
        return True

    # Continue the loop if under recursion limit
    if recursion_depth < llm_agent.max_recursion_depth:
        # Remove color markup to use default orange foreground
        await app_instance.display_message(f"\nContinuing task...")
        # Pass the app_instance for recursive calls and await the async function
        await process_user_request(app_instance, user_input, flipper_agent, llm_agent, recursion_depth + 1)